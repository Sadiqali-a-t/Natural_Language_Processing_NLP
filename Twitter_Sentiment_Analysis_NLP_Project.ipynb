{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81dcb78a",
   "metadata": {},
   "source": [
    "# <span style = \"color:green\"> Twitter Sentiment Analysis </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75fc46",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecc522",
   "metadata": {},
   "source": [
    "Sentiment analysis refers to identifying as well as classifying the sentiments that are expressed in the text source. Tweets are often useful in generating a vast amount of sentiment data upon analysis. These data are useful in understanding the opinion of the people about a variety of topics.\n",
    "\n",
    "Therefore we need to develop an Automated Machine Learning Sentiment analysis Model in order to compute the customer perception. Due to the presence of non-useful characters (collectively termed as the noise) along with useful data, it becomes difficult to implement models on them.\n",
    "\n",
    "Here, We aim to analyze the sentiment of the tweets provided in the dataset by developing a machine learning pipeline involving the use of SVM classifier along with using Term Frequency-Inverse Document Frequency(TF-IDF). \n",
    "\n",
    "The dataset consist of 13870 tweets that have been extracted using the Twitter API. The dataset contains various columns but for this specific problem, we would only be using\n",
    "   * Sentiment - Positive, Negative, Neutral\n",
    "   * Text - Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a621f9",
   "metadata": {},
   "source": [
    "## Let's get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf7618",
   "metadata": {},
   "source": [
    "### Import Necessay Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ba321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3756fa7",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b425cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ee6da",
   "metadata": {},
   "source": [
    "### View head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a9926a",
   "metadata": {},
   "source": [
    "### View info of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c822ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69d47cc",
   "metadata": {},
   "source": [
    "### Drop all columns exept 'text' and 'sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a033fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89322c10",
   "metadata": {},
   "source": [
    "### Check all the unique values in Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b584bb",
   "metadata": {},
   "source": [
    "### Convert Neutral to 0, Positive to 1 and Negative to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(x):\n",
    "    if x == 'Neutral':\n",
    "        return 0\n",
    "    elif x == 'Positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4596747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df['sentiment'] = df['sentiment'].apply(Convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5c649",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0140ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b686e",
   "metadata": {},
   "source": [
    "### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230078c6",
   "metadata": {},
   "source": [
    "### Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb78d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep = 'first',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df13e1f",
   "metadata": {},
   "source": [
    "### View some of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(df['text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4074315",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9125851",
   "metadata": {},
   "source": [
    "### Plot a countplot of sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df, x = 'sentiment', palette='bright', hue = 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793f81b",
   "metadata": {},
   "source": [
    "### Plot a piechart to show the percentile representation of sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea926266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df['sentiment'].value_counts(), labels = ['Negative', 'Neutral','Positive'], autopct = '%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25edae9",
   "metadata": {},
   "source": [
    "### Define a function that preprocess the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65191d80",
   "metadata": {},
   "source": [
    "ie, \n",
    "* Remove all special characters\n",
    "* Remove any stopwords\n",
    "* Lemmatize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    #removes all the special characters and split the sentence at spaces\n",
    "    text = re.sub(r'[^0-9a-zA-Z]+',' ',sentence).split()\n",
    "    \n",
    "    # converts words to lowercase and removes any stopwords\n",
    "    words = [x.lower() for x in text if x not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemma = WordNetLemmatizer()\n",
    "    word = [lemma.lemmatize(word,'v') for word in words ]\n",
    "    \n",
    "    # convert the list of words back into a sentence\n",
    "    word = ' '.join(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f4150",
   "metadata": {},
   "source": [
    "### Apply the function to our tweets column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf19dc4",
   "metadata": {},
   "source": [
    "### Print some of the tweets after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f4d6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d00b71",
   "metadata": {},
   "source": [
    "### Assign X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b02afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(df['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63ea15-19a9-4d8f-ac85-f6e1f0e7c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f885b",
   "metadata": {},
   "source": [
    "### Transform X variable(tweets) using TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78edb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8604fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vector.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637b41bd",
   "metadata": {},
   "source": [
    "### Split the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8172a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35cd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f92a6",
   "metadata": {},
   "source": [
    "### Check the shape of X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67448e9d",
   "metadata": {},
   "source": [
    "### Create a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d511998",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc98f48c",
   "metadata": {},
   "source": [
    "### Check the score of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36a69e",
   "metadata": {},
   "source": [
    "### Make prediction with X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8482f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8bbeef",
   "metadata": {},
   "source": [
    "### Check the accuracy of our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6008bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5db65-606b-4bd1-aab8-1cf8d55469f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ea89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8e017",
   "metadata": {},
   "source": [
    "### Plot confusion matrix on heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61c93b-eb55-4679-abc1-53a8882c485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(metrics.confusion_matrix(y_test,y_pred), annot=True,fmt='0.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb6f7f",
   "metadata": {},
   "source": [
    "### Print Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dcb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2de5bc8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2a9c9",
   "metadata": {},
   "source": [
    "# <center><a href = \"http://edure.in/\"><span style = \"color:CornflowerBlue; font-family:Courier New;font-size:40px\">EDURE LEARNING</span></a></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
